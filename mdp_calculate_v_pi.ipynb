{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:20.395633Z",
     "start_time": "2024-12-22T21:46:19.773242Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import jax.lax as lax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from make_mdp import MDP\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:20.402143Z",
     "start_time": "2024-12-22T21:46:20.399638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_states = 100\n",
    "num_actions = 20\n",
    "num_rewards = 10\n",
    "\n",
    "discount_factor = 0.9\n",
    "\n",
    "seed = 42"
   ],
   "id": "d6c5c9a9b53e9bca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:20.643126Z",
     "start_time": "2024-12-22T21:46:20.528355Z"
    }
   },
   "cell_type": "code",
   "source": "key = random.key(seed)",
   "id": "b506dcd914304ff6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:21.057696Z",
     "start_time": "2024-12-22T21:46:20.647959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#make the MDP\n",
    "key, subkey = random.split(key)\n",
    "mdp = MDP(subkey, num_states, num_actions, num_rewards)\n",
    "del subkey"
   ],
   "id": "11d82b656f9ef048",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:21.151007Z",
     "start_time": "2024-12-22T21:46:21.064055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#policy matrix: num_states X num_actions with sum(policy[i,:]) == 1\n",
    "key, subkey = random.split(key)\n",
    "policy = random.uniform(subkey, [num_states, num_actions])\n",
    "del subkey\n",
    "\n",
    "policy = policy / policy.sum(axis=-1, keepdims=True)"
   ],
   "id": "f6c7476810766157",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Iterative Policy Evaluation",
   "id": "2796c2f4f90eef58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:21.159443Z",
     "start_time": "2024-12-22T21:46:21.157330Z"
    }
   },
   "cell_type": "code",
   "source": "eps = 10**(-5)",
   "id": "5ca9f4939be64a8e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:46:21.225843Z",
     "start_time": "2024-12-22T21:46:21.164778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#random initialization\n",
    "key, subkey = random.split(key)\n",
    "v_pi_0 = random.uniform(subkey, num_states, dtype=jnp.float32)"
   ],
   "id": "4fac072b8562cdeb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In Sutton and Barto we have the update rule (p.74):\n",
    "$$v_{k+1}(s) = \\sum_a \\pi(a|s) \\sum_{s',r} p(s',r|s,a) [r + \\gamma v_k(s')]$$\n",
    "\n",
    "Since our MDP is not defined via the four argument probability $p(s',r|s,a)$ but rather state transitions $p(s'|s,a)$ and reward probabilities $p(r|s,a)$ we rewrite this as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{k+1}(s) &= \\sum_a \\pi(a|s) \\sum_{s',r} p(s',r|s,a) [r + \\gamma v_k(s')]\\\\\n",
    "           &= \\sum_a \\pi(a|s) [\\sum_{s',r} p(s',r|s,a) r + \\gamma \\sum_{s',r} p(s',r|s,a) v_k(s')]\\\\\n",
    "           &= \\sum_a \\pi(a|s) [\\sum_{r} r \\sum_{s'} p(s',r|s,a) + \\gamma \\sum_{s'} v_k(s') sum_{r} p(s',r|s,a) ]\\\\\n",
    "           &= \\sum_a \\pi(a|s) [\\sum_{r} r p(r|s,a) + \\gamma \\sum_{s'} v_k(s') p(s'|s,a) ]\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$\\sum_{r} r p(r|s,a)$ is simply the expected reward when choosing action $a$ at state $s$. This is pre-computed as `mdp.expected_rewards`.\n",
    "$\\gamma \\sum_{s'} v_k(s') p(s'|s,a)$ is the discounted expectation of the value over the next states when choosing action $a$. \n"
   ],
   "id": "82e844db8c885058"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simple while-loop implementation (synchronous updates)",
   "id": "ae5a01313f2bdd7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:47:08.356887Z",
     "start_time": "2024-12-22T21:46:21.230795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v_pi = jnp.copy(v_pi_0)\n",
    "num_iterations = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "while True:\n",
    "    num_iterations += 1\n",
    "    \n",
    "    delta = 0\n",
    "    v_pi_old = jnp.copy(v_pi)\n",
    "    for s in range(num_states):\n",
    "        v_pi_s = 0\n",
    "        for a in range(num_actions):\n",
    "            policy_s_a = policy[s, a]\n",
    "            v_pi_s += policy_s_a * mdp.expected_rewards[s,a]\n",
    "            v_pi_s += policy_s_a * discount_factor * jnp.dot(v_pi_old, mdp.transition_ps[s, a, :])\n",
    "        v_pi = v_pi.at[s].set(v_pi_s)\n",
    "\n",
    "        delta = max(delta, jnp.abs(v_pi_old[s] - v_pi[s]))\n",
    "    \n",
    "    if delta < eps:\n",
    "        break\n",
    "\n",
    "_ = v_pi.block_until_ready()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_loop = end - start\n",
    "print(f\"Iterations {num_iterations} - Delta {delta:.5f} - Time: {elapsed_loop:.6f} seconds\")\n",
    "print(f\"Value function:\\n{v_pi}\")\n"
   ],
   "id": "9e7643b87b7bc21f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 102 - Delta 0.00001 - Time: 47.114200 seconds\n",
      "Value function:\n",
      "[-3.2662337 -3.3299084 -3.3180332 -3.3560042 -3.3961449 -3.3184109\n",
      " -3.2981157 -3.248808  -3.2935073 -3.3894188 -3.235799  -3.3393154\n",
      " -3.2018504 -3.2801137 -3.3524525 -3.3262892 -3.3367422 -3.232171\n",
      " -3.3092735 -3.3093662 -3.2834554 -3.3123755 -3.2620194 -3.3356605\n",
      " -3.2462163 -3.382313  -3.3461382 -3.285791  -3.3369431 -3.247228\n",
      " -3.2327912 -3.2193506 -3.3057892 -3.4036007 -3.263416  -3.30798\n",
      " -3.3137524 -3.2604678 -3.3193526 -3.1980562 -3.3333912 -3.285531\n",
      " -3.2656493 -3.3021815 -3.349827  -3.3334477 -3.3454044 -3.303187\n",
      " -3.3416786 -3.314237  -3.391325  -3.3518615 -3.293537  -3.3242981\n",
      " -3.2234306 -3.3435624 -3.3045456 -3.459414  -3.296707  -3.221883\n",
      " -3.2616482 -3.346547  -3.31943   -3.3207636 -3.3269696 -3.3348448\n",
      " -3.232609  -3.3307145 -3.302874  -3.3285286 -3.2192764 -3.2927485\n",
      " -3.3426578 -3.3128083 -3.2812192 -3.3572512 -3.2607646 -3.2218995\n",
      " -3.3352025 -3.3484054 -3.3573203 -3.2814257 -3.3321078 -3.3095415\n",
      " -3.3844786 -3.2685597 -3.2243092 -3.3802464 -3.3043935 -3.3110948\n",
      " -3.2460277 -3.315837  -3.3691142 -3.3520772 -3.3176243 -3.2873685\n",
      " -3.2794244 -3.4097655 -3.1968076 -3.3105578]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lax-While Loop",
   "id": "dcb4b0b4d234acf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:47:31.227285Z",
     "start_time": "2024-12-22T21:47:08.432158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def iterative_value_estimation(state):\n",
    "    delta, v_pi, iteration = state\n",
    "    delta = 0\n",
    "    iteration += 1\n",
    "    v_pi_old = jnp.copy(v_pi)\n",
    "    for s in range(num_states):\n",
    "        v_pi_s = 0\n",
    "        for a in range(num_actions):\n",
    "            policy_s_a = policy[s, a]\n",
    "            v_pi_s += policy_s_a * mdp.expected_rewards[s,a]\n",
    "            v_pi_s += policy_s_a * discount_factor * jnp.dot(v_pi_old, mdp.transition_ps[s, a, :])\n",
    "        v_pi = v_pi.at[s].set(v_pi_s)\n",
    "\n",
    "        delta = jnp.maximum(delta, jnp.abs(v_pi_old[s] - v_pi[s]))\n",
    "    return (delta, v_pi, iteration)\n",
    "\n",
    "def cond_function(state):\n",
    "    delta, v_pi, _ = state\n",
    "    return delta > eps\n",
    "\n",
    "v_pi = jnp.copy(v_pi_0)\n",
    "init_state = (1e13, v_pi, 0)\n",
    "\n",
    "start = time.time()\n",
    "delta, v_pi, num_iterations = lax.while_loop(cond_function, iterative_value_estimation, init_state)\n",
    "end = time.time()\n",
    "\n",
    "elapsed_lax_loop = end - start\n",
    "print(f\"Iterations {num_iterations} - Delta {delta:.5f} - Time: {elapsed_lax_loop:.6f} seconds\")\n",
    "print(f\"Value function:\\n{v_pi}\")"
   ],
   "id": "9825982451a87a29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 102 - Delta 0.00001 - Time: 22.735680 seconds\n",
      "Value function:\n",
      "[-3.2662337 -3.3299081 -3.3180335 -3.3560042 -3.3961449 -3.3184109\n",
      " -3.2981157 -3.248808  -3.2935073 -3.3894188 -3.235799  -3.3393154\n",
      " -3.2018502 -3.280114  -3.3524525 -3.3262892 -3.3367424 -3.2321708\n",
      " -3.3092732 -3.3093665 -3.2834554 -3.3123758 -3.2620196 -3.3356605\n",
      " -3.246216  -3.382313  -3.3461382 -3.285791  -3.3369431 -3.2472274\n",
      " -3.2327914 -3.2193506 -3.3057892 -3.4036007 -3.263416  -3.3079803\n",
      " -3.3137522 -3.2604678 -3.3193529 -3.1980562 -3.3333912 -3.2855313\n",
      " -3.2656496 -3.3021815 -3.349827  -3.3334477 -3.3454046 -3.303187\n",
      " -3.3416789 -3.3142374 -3.391325  -3.3518615 -3.293537  -3.324298\n",
      " -3.2234306 -3.3435624 -3.3045456 -3.4594138 -3.296707  -3.221883\n",
      " -3.2616484 -3.346547  -3.31943   -3.3207636 -3.3269696 -3.3348446\n",
      " -3.232609  -3.3307145 -3.302874  -3.3285286 -3.2192767 -3.2927487\n",
      " -3.342658  -3.3128083 -3.2812192 -3.357251  -3.2607646 -3.2218995\n",
      " -3.3352025 -3.3484054 -3.3573205 -3.2814257 -3.332108  -3.3095415\n",
      " -3.3844786 -3.2685595 -3.2243092 -3.3802464 -3.3043935 -3.3110948\n",
      " -3.246028  -3.315837  -3.3691142 -3.3520775 -3.3176243 -3.2873685\n",
      " -3.2794244 -3.409766  -3.1968076 -3.3105578]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vectorized update in lax loop\n",
   "id": "2eda50252b24accd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:47:31.383471Z",
     "start_time": "2024-12-22T21:47:31.306550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vectorized_value_estimation(state):\n",
    "    delta, v_pi, iteration = state\n",
    "    iteration += 1\n",
    "    expected_r = jnp.sum(policy * mdp.expected_rewards, axis=1)\n",
    "    expected_v = jnp.sum(policy[:, :, None] * mdp.transition_ps * v_pi[None, None, :], axis=(1,2)) \n",
    "    v_pi_new = expected_r + discount_factor * expected_v\n",
    "    delta = jnp.max(jnp.abs(v_pi_new - v_pi))\n",
    "    return (delta, v_pi_new, iteration)\n",
    "\n",
    "def cond_function(state):\n",
    "    delta, v_pi, _ = state\n",
    "    return delta > eps\n",
    "\n",
    "v_pi = jnp.copy(v_pi_0)\n",
    "init_state = (1e13, v_pi, 0)\n",
    "\n",
    "start = time.time()\n",
    "delta, v_pi, num_iterations = lax.while_loop(cond_function, vectorized_value_estimation, init_state)\n",
    "end = time.time()\n",
    "\n",
    "elapsed_vectorized_lax_loop = end - start\n",
    "print(f\"Iterations {num_iterations} - Delta {delta:.5f} - Time: {elapsed_vectorized_lax_loop:.6f} seconds\")\n",
    "print(f\"Value function:\\n{v_pi}\")"
   ],
   "id": "f30631d92e51bef3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 102 - Delta 0.00001 - Time: 0.058187 seconds\n",
      "Value function:\n",
      "[-3.2662337 -3.3299072 -3.3180332 -3.3560035 -3.396145  -3.3184102\n",
      " -3.2981155 -3.248808  -3.2935073 -3.3894188 -3.2357981 -3.339315\n",
      " -3.2018507 -3.280114  -3.3524525 -3.326289  -3.3367424 -3.2321703\n",
      " -3.3092737 -3.3093657 -3.283455  -3.3123758 -3.2620194 -3.3356597\n",
      " -3.2462156 -3.382313  -3.346137  -3.2857904 -3.3369431 -3.2472284\n",
      " -3.2327907 -3.2193508 -3.305789  -3.4036007 -3.2634163 -3.3079803\n",
      " -3.3137517 -3.2604675 -3.3193517 -3.198056  -3.3333912 -3.2855313\n",
      " -3.2656493 -3.3021815 -3.3498266 -3.333447  -3.3454049 -3.3031862\n",
      " -3.341679  -3.3142369 -3.3913245 -3.3518612 -3.2935371 -3.3242974\n",
      " -3.2234302 -3.3435621 -3.3045452 -3.459414  -3.2967062 -3.2218835\n",
      " -3.2616484 -3.3465466 -3.3194304 -3.3207629 -3.3269691 -3.3348444\n",
      " -3.232609  -3.330715  -3.302874  -3.3285284 -3.219276  -3.2927477\n",
      " -3.3426578 -3.3128092 -3.2812183 -3.3572512 -3.2607644 -3.221899\n",
      " -3.3352032 -3.3484051 -3.3573198 -3.281426  -3.3321078 -3.309542\n",
      " -3.384478  -3.2685597 -3.2243087 -3.3802464 -3.3043935 -3.311095\n",
      " -3.246028  -3.3158374 -3.3691137 -3.3520777 -3.3176248 -3.2873683\n",
      " -3.2794247 -3.409766  -3.1968074 -3.3105578]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:47:31.397942Z",
     "start_time": "2024-12-22T21:47:31.393665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Simple Loop: {elapsed_loop:.6f} seconds')\n",
    "print(f'Lax Loop: {elapsed_lax_loop:.6f} seconds')\n",
    "print(f'Vectorized Lax Loop: {elapsed_vectorized_lax_loop:.6f} seconds')"
   ],
   "id": "4ed5f4653a8dc53c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Loop: 47.114200 seconds\n",
      "Lax Loop: 22.735680 seconds\n",
      "Vectorized Lax Loop: 0.058187 seconds\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
